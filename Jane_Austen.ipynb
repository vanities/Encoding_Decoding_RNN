{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam Mischke\n",
    "#### CSCI 4850-5850 - Neural Networks\n",
    "#### Open Lab 3\n",
    "#### Due: Apr. 19 @ 11:00pm (I tried)\n",
    "#### General Sequence-to-Sequence Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csci4850/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import keras\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "% matplotlib inline \n",
    "\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "# Visualization \n",
    "from IPython.display import SVG \n",
    "from IPython.display import display \n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Utilize the methods learned in the tutorial above to train an encoder-decoder network to solve the P&P text learning problem usingthe first 50 sentences from the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data and prepare the data as described above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of sentences: 10658\n",
      "longest sentence: 76\n",
      "number of tokens: 71\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "with open('/home/share/gutenberg_example/PandP_Jane_Austen.txt','r',encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "text=[]\n",
    "for i in range(len(lines)):\n",
    "    if lines[i]!='':\n",
    "        text=text+[lines[i]]\n",
    "min_length=max([len(i) for i in text])\n",
    "\n",
    "# unique characters\n",
    "with open('/home/share/gutenberg_example/unique_chars.txt','r',encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    \n",
    "# integer code to symbol\n",
    "itos = ['', '', ' ']\n",
    "\n",
    "for i in lines:\n",
    "    itos = itos + [i]\n",
    "    \n",
    "# symbol to integer code\n",
    "stoi = dict()\n",
    "stoi['STOP'] = 0\n",
    "stoi['START'] = 1\n",
    "\n",
    "for i in range(2, len(itos)):\n",
    "    stoi[itos[i]] = i\n",
    "        \n",
    "# total number of sentences\n",
    "print('total number of sentences:', len(text))\n",
    "\n",
    "# longest sentence\n",
    "print('longest sentence:', max(len(i) for i in text) + 2)\n",
    "\n",
    "# number of tokens\n",
    "print('number of tokens:', len(itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntemp = encode_seq(text[0], stoi)\\ntemp = decode_seq(temp, itos)\\nprint('before encoded:', text[0])\\nprint('decoded:', temp)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up our one-hot encoding and decoding functions\n",
    "\n",
    "def encode_seq(x,mapping,min_length=0):\n",
    "    # String to one-hot\n",
    "    y=[mapping['START']]\n",
    "    for i in list(x):\n",
    "        y=y+[mapping[i]]\n",
    "    y=y+[mapping['STOP']]\n",
    "    # Stop-padding - handled elsewhere...\n",
    "    while len(y)<min_length:\n",
    "        y=y+[mapping['STOP']]\n",
    "    return keras.utils.to_categorical(y,len(mapping))\n",
    "    \n",
    "def decode_seq(x,mapping):\n",
    "    # One-hot to string\n",
    "    y=[] \n",
    "    for i in x:\n",
    "        y=y+[mapping[np.argmax(i)]]\n",
    "    return ''.join(y)\n",
    "\n",
    "# checking to make sure our encoding/decoding works\n",
    "# by encoding - decoding cycle on the first line\n",
    "\"\"\"\n",
    "temp = encode_seq(text[0], stoi)\n",
    "temp = decode_seq(temp, itos)\n",
    "print('before encoded:', text[0])\n",
    "print('decoded:', temp)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines: 50\n",
      "X shape: (50, 76, 71)\n",
      "Y shape: (50, 76, 71)\n",
      "preY shape: (50, 75, 71)\n",
      "postY shape: (50, 75, 71)\n"
     ]
    }
   ],
   "source": [
    "# encode the data\n",
    "dataX=np.ones([len(text),max([len(i) for i in text])+2,len(itos)])*(1.0/len(itos))\n",
    "\n",
    "for i in range(len(text)):\n",
    "    temp=encode_seq(text[i],stoi)\n",
    "    dataX[i,0:len(temp),:]=temp\n",
    "\n",
    "# set Y as well\n",
    "dataY=np.ones([len(text),max([len(i)for i in text])+2,len(itos)])*(1.0/len(itos)) \n",
    "for i in range(len(text)):\n",
    "    temp=encode_seq(text[i],stoi)\n",
    "    dataY[i,0:len(temp),:]=temp\n",
    "    \n",
    "    \n",
    "X=dataX[0:dataX.shape[0]-1,:,:]\n",
    "Y=dataY[1:dataY.shape[0],:,:]\n",
    "preY=Y[:,0:Y.shape[1]-1,:]\n",
    "postY=Y[:,1:Y.shape[1],:]\n",
    "\n",
    "\n",
    "nlines=50\n",
    "X=X[0:nlines,:,:]\n",
    "Y=Y[0:nlines,:,:]\n",
    "preY=preY[0:nlines,:,:]\n",
    "postY=postY[0:nlines,:,:]\n",
    "\n",
    "print('Number of lines:', nlines)\n",
    "print('X shape:', X.shape)\n",
    "print('Y shape:', Y.shape)\n",
    "print('preY shape:', preY.shape)\n",
    "print('postY shape:', postY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the encoder-decoder network for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 71)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 71)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 760),  2529280     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 760),  2529280     input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 71)     54031       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 5,112,591\n",
      "Trainable params: 5,112,591\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#activation = 'relu'\n",
    "#activation = 'softsign'\n",
    "activation = 'tanh'\n",
    "\n",
    "input_length = max(len(i) for i in text) + 2\n",
    "# size of gestalt context representation\n",
    "# (76 * 6 = 456)\n",
    "hidden_size = input_length * 10\n",
    "\n",
    "# encoder construction\n",
    "# make layers\n",
    "encoder_input = keras.layers.Input(shape= (None, X.shape[2]))\n",
    "\n",
    "encoder_hidden = keras.layers.LSTM(hidden_size, return_state = True, return_sequences = True, activation=activation)\n",
    "#encoder_hidden = keras.layers.Dropout(0.25)(encoder_hidden)\n",
    "\n",
    "# tie the hidden layer to the input layer\n",
    "encoder_output, enc_state_h, enc_state_c = encoder_hidden(encoder_input)\n",
    "# discard encoder outputs and keep only the states\n",
    "encoder_states = [enc_state_h, enc_state_c]\n",
    "\n",
    "# decoder construction\n",
    "# set up the decoder using encoder states as the initial state\n",
    "decoder_input = keras.layers.Input(shape= (None, preY.shape[2]))\n",
    "decoder_hidden = keras.layers.LSTM(hidden_size, return_sequences = True, return_state = True, activation=activation)\n",
    "\n",
    "# connect hidden to input\n",
    "decoder_hidden_output, decoder_state_h, decoder_state_c = decoder_hidden(decoder_input, initial_state = encoder_states)\n",
    "\n",
    "\n",
    "decoder_dense = keras.layers.Dense(postY.shape[2], activation = 'softmax')\n",
    "\n",
    "# connect output to hidden\n",
    "decoder_output = decoder_dense(decoder_hidden_output)\n",
    "\n",
    "# Our functoinal API model now has two input layers..\n",
    "# 1. reads from X\n",
    "# 2. reads from preY\n",
    "# single output layer\n",
    "# 1. targets are postY\n",
    "model = keras.Model([encoder_input, decoder_input], decoder_output)\n",
    "\n",
    "# compile it\n",
    "model.compile(loss = keras.losses.categorical_crossentropy,\n",
    "              optimizer = keras.optimizers.Adam(lr = 0.001),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"264pt\" viewBox=\"0.00 0.00 263.00 264.00\" width=\"263pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 260)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-260 259,-260 259,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140669473222048 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140669473222048</title>\n",
       "<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 125,-255.5 125,-219.5 0,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-233.8\">input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140669477840600 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140669477840600</title>\n",
       "<polygon fill=\"none\" points=\"13.5,-146.5 13.5,-182.5 111.5,-182.5 111.5,-146.5 13.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-160.8\">lstm_1: LSTM</text>\n",
       "</g>\n",
       "<!-- 140669473222048&#45;&gt;140669477840600 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140669473222048-&gt;140669477840600</title>\n",
       "<path d=\"M62.5,-219.313C62.5,-211.289 62.5,-201.547 62.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"66.0001,-192.529 62.5,-182.529 59.0001,-192.529 66.0001,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140669477840712 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140669477840712</title>\n",
       "<polygon fill=\"none\" points=\"130,-146.5 130,-182.5 255,-182.5 255,-146.5 130,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192.5\" y=\"-160.8\">input_2: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140669473018040 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140669473018040</title>\n",
       "<polygon fill=\"none\" points=\"78.5,-73.5 78.5,-109.5 176.5,-109.5 176.5,-73.5 78.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-87.8\">lstm_2: LSTM</text>\n",
       "</g>\n",
       "<!-- 140669477840712&#45;&gt;140669473018040 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140669477840712-&gt;140669473018040</title>\n",
       "<path d=\"M176.765,-146.313C168.701,-137.505 158.741,-126.625 149.892,-116.958\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"152.424,-114.541 143.09,-109.529 147.261,-119.268 152.424,-114.541\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140669477840600&#45;&gt;140669473018040 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140669477840600-&gt;140669473018040</title>\n",
       "<path d=\"M78.2347,-146.313C86.2986,-137.505 96.2588,-126.625 105.108,-116.958\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107.739,-119.268 111.91,-109.529 102.576,-114.541 107.739,-119.268\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140668550648552 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140668550648552</title>\n",
       "<polygon fill=\"none\" points=\"76.5,-0.5 76.5,-36.5 178.5,-36.5 178.5,-0.5 76.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-14.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 140669473018040&#45;&gt;140668550648552 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140669473018040-&gt;140668550648552</title>\n",
       "<path d=\"M127.5,-73.3129C127.5,-65.2895 127.5,-55.5475 127.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"131,-46.5288 127.5,-36.5288 124,-46.5289 131,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualization \n",
    "SVG(model_to_dot(model).create(prog='dot',format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train your network (include the loss and accuracy plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dea5c0145644d3d833c1aec0bbc1b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1deadfafd14d34a3f74e8c628e6fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50/50 [==============================] - 4s 89ms/step\n",
      "Accuracy: 78.23999977111816 %\n"
     ]
    }
   ],
   "source": [
    "# 50/2 = 25 batches\n",
    "batch_size=nlines // 2\n",
    "# number of time steps\n",
    "epochs=200\n",
    "\n",
    "# train\n",
    "history=model.fit([X,preY],postY,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  verbose=0,\n",
    "                  callbacks=[TQDMNotebookCallback()])\n",
    "\n",
    "# evaluate\n",
    "print('Accuracy:',model.evaluate([X,preY],postY)[1]*100.0,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff0e42e4908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "\n",
    "plt.figure(1)\n",
    "# summarize history for accuracy\n",
    "plt.subplot(211)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "# summarize history for loss\n",
    "plt.subplot(212)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build your encoder_model and decoder_model tesing networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "# Part 1 - make the encoder\n",
    "# make just a model out of the encoder\n",
    "# input = encoder_input (Input layer)\n",
    "# output = encoder_states (enc Hidden layer * 2)\n",
    "encoder_model=keras.Model(encoder_input, encoder_states)\n",
    "\n",
    "# Part 2 - make the decoder\n",
    "# make just a model out of the decoder\n",
    "# input = encoder_states (enc Hidden layer * 2)\n",
    "# output = decoder_output\n",
    "decoder_state_input_h=keras.layers.Input(shape=(hidden_size,))\n",
    "decoder_state_input_c=keras.layers.Input(shape=(hidden_size,))\n",
    "\n",
    "# connect hidden to input\n",
    "decoder_states_input=[decoder_state_input_h,decoder_state_input_c]\n",
    "decoder_hidden_output,decoder_state_h,decoder_state_c = decoder_hidden(decoder_input,\n",
    "                                                                       initial_state=decoder_states_input)\n",
    "decoder_states=[decoder_state_h,decoder_state_c]\n",
    "\n",
    "# connect output to hidden\n",
    "decoder_output=decoder_dense(decoder_hidden_output)\n",
    "decoder_model=keras.Model(\n",
    "    [decoder_input]+decoder_states_input,\n",
    "    [decoder_output]+decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the gestalt context for the input sequence(s)\n",
    "i=0\n",
    "context=encoder_model.predict(X[i:i+1,:,:])\n",
    "\n",
    "# prep a starting token...\n",
    "token=encode_seq('',stoi)[0].reshape(1,1,len(stoi))\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: It is a truth universally acknowledged, that a single man in possession\n",
      "Output: of a good fortune, must be in want of a wife.\n"
     ]
    }
   ],
   "source": [
    "# What should we see?\n",
    "print('Input:',text[i])\n",
    "print('Output:',text[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' o o ot o tha at teeo o w be snere '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Complete max cycles with the decoder\n",
    "result=np.zeros([1,postY.shape[1],postY.shape[2]])\n",
    "for x in range(postY.shape[1]):\n",
    "    out,h,c=decoder_model.predict([token]+context)\n",
    "    token=np.round(out)\n",
    "    context=[h,c]\n",
    "    result[:,x,:]=token\n",
    "    \n",
    "decode_seq(result[0,:,:],itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test your networks using teacher forcing (50 sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate - teacher forcing through each line\n",
    "for i in range(0,nlines):\n",
    "    # Get the gestalt context for the input sequence(s)\n",
    "    context=encoder_model.predict(X[i:i+1,:,:])\n",
    "    \n",
    "    # Prep a starting token...\n",
    "    token=encode_seq('',stoi)[0].reshape(1,1,len(stoi))\n",
    "    \n",
    "    result=np.zeros([1,postY.shape[1],postY.shape[2]])\n",
    "    \n",
    "    \"\"\"\n",
    "    for x in range(postY.shape[1]):\n",
    "        out,h,c = decoder_model.predict([token]+context)\n",
    "        token[:,:,:] = 0.0\n",
    "        token[:,:,np.argmax(out)] = 1.0\n",
    "        context = [h,c]\n",
    "        result[:,x,:] = token\n",
    "        if decode_seq(token,itos) == '':\n",
    "            break\n",
    "    \"\"\"\n",
    "    \n",
    "    for x in range(postY.shape[1]):\n",
    "        out,h,c=decoder_model.predict([token]+context)\n",
    "        token=np.round(out)\n",
    "        context=[h,c]\n",
    "        result[:,x,:]=token\n",
    "    \n",
    "    \n",
    "    print('Txt:',text[i+1])\n",
    "    print('Net:',decode_seq(result[0,:,:],itos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test your networks without teacher forcing (50 sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate - but no teaching forcing past first line...\n",
    "# Get the gestalt context for the input sequence\n",
    "i=0\n",
    "context=encoder_model.predict(X[i:i+1,:,:])\n",
    "for i in range(0,nlines):\n",
    "    # Prep a starting token...\n",
    "    token=encode_seq('',stoi)[0].reshape(1,1,len(stoi))\n",
    "    \n",
    "    result=np.zeros([1,postY.shape[1],postY.shape[2]])\n",
    "    \"\"\"\n",
    "    for x in range(postY.shape[1]):\n",
    "        out,h,c = decoder_model.predict([token]+context)\n",
    "        token[:,:,:] = 0.0\n",
    "        token[:,:,np.argmax(out)] = 1.0\n",
    "        context = [h,c]\n",
    "        result[:,x,:] = token\n",
    "        if decode_seq(token,itos) == '':\n",
    "            break\n",
    "    \n",
    "    \"\"\"\n",
    "    for x in range(postY.shape[1]):\n",
    "        out,h,c=decoder_model.predict([token]+context)\n",
    "        token=np.round(out)\n",
    "        context=[h,c]\n",
    "        result[:,x,:]=token\n",
    "    \n",
    "    print('Txt:',text[i+1])\n",
    "    print('Net:',decode_seq(result[0,:,:],itos))\n",
    "    \n",
    "    # CRUCIAL -> keep predicted result instead of teacher forcing!\n",
    "    context=encoder_model.predict(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Load up the P&P data again, but this time split the data intowords instead oflines. By words I simply meandivided by whitespace,so you can have words that only contain punctuation. Utilize the methods learned in the tutorial above to train an encoder-decodernetwork to solve the P&P text learning problem using the first 500 words in the text. You will be using one word to predict the next word. (Critical note:words are significantly shorter than lines, so the number of time steps used by your network is farreduced and will significantly decrease the training time required.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data and prepare the data as described above (split into words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing - grab lines from the file\n",
    "\n",
    "import string\n",
    "\n",
    "nwords = 500\n",
    "\n",
    "table = str.maketrans({key: None for key in string.punctuation})\n",
    "\n",
    "with open('/home/share/gutenberg_example/PandP_Jane_Austen.txt','r',encoding='utf-8') as f:\n",
    "    lines = f.read().replace(' ', '\\n').split('\\n')\n",
    "# Paragraphs are separated by blank\n",
    "# lines -> just drop those lines...\n",
    "text=[]\n",
    "\n",
    "lines = [i.translate(table) for i in lines]\n",
    "lines = [i for i in lines if i]\n",
    "\n",
    "text = lines[:nwords+1]\n",
    "\n",
    "min_length=max([len(i) for i in text])\n",
    "\n",
    "\n",
    "# unique characters - precalculated\n",
    "with open('/home/share/gutenberg_example/unique_chars.txt','r',encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    \n",
    "# integer code to symbol\n",
    "itos = ['', '', ' ']\n",
    "\n",
    "for i in lines:\n",
    "    itos = itos + [i]\n",
    "    \n",
    "# symbol to integer code\n",
    "stoi = dict()\n",
    "stoi['STOP'] = 0\n",
    "stoi['START'] = 1\n",
    "\n",
    "for i in range(2, len(itos)):\n",
    "    stoi[itos[i]] = i\n",
    "    \n",
    "# total number of words\n",
    "print('total number of words:', len(text))\n",
    "\n",
    "# longest word\n",
    "print(max(len(i) for i in text) + 2)\n",
    "\n",
    "# number of tokens\n",
    "print(len(itos))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the encoder-decoder network for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode that data\n",
    "dataX=np.ones([len(text),max([len(i) for i in text])+2,len(itos)])*(1.0/len(itos))\n",
    "\n",
    "for i in range(len(text)):\n",
    "    temp=encode_seq(text[i],stoi, min_length)\n",
    "    dataX[i,0:len(temp),:]=temp\n",
    "    \n",
    "# Not strictly necessary, but I was trying some alternative strategies\n",
    "# earlier and this is worth keeping around...\n",
    "# This will be the same as dataX using this implementation...\n",
    "dataY=np.ones([len(text),max([len(i)for i in text])+2,len(itos)])*(1.0/len(itos)) \n",
    "for i in range(len(text)):\n",
    "    temp=encode_seq(text[i],stoi, min_length)\n",
    "    dataY[i,0:len(temp),:]=temp\n",
    "    \n",
    "    \n",
    "X=dataX[0:dataX.shape[0]-1,:,:]\n",
    "Y=dataY[1:dataY.shape[0],:,:]\n",
    "preY=Y[:,0:Y.shape[1]-1,:]\n",
    "postY=Y[:,1:Y.shape[1],:]\n",
    "\n",
    "\n",
    "X=X[0:nwords,:,:]\n",
    "Y=Y[0:nwords,:,:]\n",
    "preY=preY[0:nwords,:,:]\n",
    "postY=postY[0:nwords,:,:]\n",
    "\n",
    "print('Number of words:', nwords)\n",
    "print('X shape:', X.shape)\n",
    "print('Y shape:', Y.shape)\n",
    "print('preY shape:', preY.shape)\n",
    "print('postY shape:', postY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation = 'relu'\n",
    "activation = 'tanh'\n",
    "\n",
    "input_length = max(len(i) for i in text) + 2\n",
    "# size of gestalt context representation\n",
    "hidden_size = input_length * 20\n",
    "\n",
    "# encoder construction\n",
    "# make layers\n",
    "encoder_input = keras.layers.Input(shape= (None, X.shape[2]))\n",
    "encoder_hidden = keras.layers.LSTM(hidden_size, return_state = True, activation=activation)\n",
    "\n",
    "#DOUBLE\n",
    "#encoder_hidden = keras.layers.LSTM(hidden_size, return_sequences = True, return_state = True, activation = activation)\n",
    "#encoder_hidden2 = keras.layers.LSTM(hidden_size,  return_state = True, activation = activation)\n",
    "\n",
    "\n",
    "# tie the hidden layer to the input layer\n",
    "encoder_output, enc_state_h, enc_state_c = encoder_hidden(encoder_input)\n",
    "# discard encoder outputs and keep only the states\n",
    "encoder_states = [enc_state_h, enc_state_c]\n",
    "\n",
    "#encoder_output2, enc_state_h2, enc_state_c2 = encoder_hidden2(encoder_hidden(encoder_input))\n",
    "\n",
    "# discard encoder outputs and keep only the states\n",
    "#encoder_states2 = [enc_state_h2, enc_state_c2]\n",
    "\n",
    "\n",
    "# decoder construction\n",
    "# set up the decoder using encoder states as the initial state\n",
    "decoder_input = keras.layers.Input(shape= (None, preY.shape[2]))\n",
    "decoder_hidden = keras.layers.LSTM(hidden_size, return_sequences = True, return_state = True, activation=activation)\n",
    "#decoder_hidden2 = keras.layers.LSTM(hidden_size,  return_sequences = True, return_state = True, activation = activation)\n",
    "\n",
    "\n",
    "\n",
    "# connect hidden to input\n",
    "decoder_hidden_output, decoder_state_h, decoder_state_c = decoder_hidden(decoder_input, initial_state = encoder_states)\n",
    "#decoder_hidden_output2, decoder_state_h2, decoder_state_c2 = decoder_hidden2(decoder_hidden(decoder_input, initial_state = encoder_states2))\n",
    "\n",
    "\n",
    "decoder_dense = keras.layers.Dense(postY.shape[2], activation = 'softmax')\n",
    "\n",
    "# connect output to hidden\n",
    "decoder_output = decoder_dense(decoder_hidden_output)\n",
    "\n",
    "# functoinal API model now has two input layers..\n",
    "# 1. reads from X\n",
    "# 2. reads from preY\n",
    "# single output layer\n",
    "#1. targets are postY\n",
    "model = keras.Model([encoder_input, decoder_input], decoder_output)\n",
    "\n",
    "# compile it\n",
    "model.compile(loss = keras.losses.categorical_crossentropy,\n",
    "              optimizer = keras.optimizers.Adam(),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train your network (include the loss and accuracy plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "batch_size=nwords // 5\n",
    "# number of patterns...\n",
    "epochs=45\n",
    "\n",
    "\n",
    "history=model.fit([X,preY],postY,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  verbose=0,\n",
    "                  callbacks=[TQDMNotebookCallback()])\n",
    "\n",
    "print('Accuracy:',model.evaluate([X,preY],postY)[1]*100.0,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "plt.figure(1)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build your encoder_model and decoder_model tesing networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "# Part 1 - make the encoder\n",
    "# Make just a model out of the encoder\n",
    "# input = encoder_input (Input layer)\n",
    "# output = encoder_states (enc Hidden layer * 2)\n",
    "encoder_model=keras.Model(encoder_input, encoder_states)\n",
    "\n",
    "# Part 2 - make the decoder\n",
    "# Make just a model out of the decoder\n",
    "# input = encoder_states (enc Hidden layer * 2)\n",
    "# output = decoder_output\n",
    "decoder_state_input_h=keras.layers.Input(shape=(hidden_size,))\n",
    "decoder_state_input_c=keras.layers.Input(shape=(hidden_size,))\n",
    "\n",
    "# Connect hidden to input(s)\n",
    "decoder_states_input=[decoder_state_input_h,decoder_state_input_c]\n",
    "decoder_hidden_output,decoder_state_h,decoder_state_c = decoder_hidden(decoder_input,\n",
    "                                                                       initial_state=decoder_states_input)\n",
    "decoder_states=[decoder_state_h,decoder_state_c]\n",
    "\n",
    "# Connect output to hidden(s)\n",
    "decoder_output=decoder_dense(decoder_hidden_output)\n",
    "decoder_model=keras.Model([decoder_input]+decoder_states_input,[decoder_output]+decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test your networks using teacher forcing (500 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Txt: is\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: truth\n",
      "Net: the\n",
      "Txt: universally\n",
      "Net: the\n",
      "Txt: acknowledged\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: single\n",
      "Net: the\n",
      "Txt: man\n",
      "Net: the\n",
      "Txt: in\n",
      "Net: the\n",
      "Txt: possession\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: good\n",
      "Net: the\n",
      "Txt: fortune\n",
      "Net: the\n",
      "Txt: must\n",
      "Net: the\n",
      "Txt: be\n",
      "Net: the\n",
      "Txt: in\n",
      "Net: the\n",
      "Txt: want\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: wife\n",
      "Net: the\n",
      "Txt: However\n",
      "Net: the\n",
      "Txt: little\n",
      "Net: the\n",
      "Txt: known\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: feelings\n",
      "Net: the\n",
      "Txt: or\n",
      "Net: the\n",
      "Txt: views\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: such\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: man\n",
      "Net: the\n",
      "Txt: may\n",
      "Net: the\n",
      "Txt: be\n",
      "Net: the\n",
      "Txt: on\n",
      "Net: the\n",
      "Txt: his\n",
      "Net: the\n",
      "Txt: first\n",
      "Net: the\n",
      "Txt: entering\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: neighbourhood\n",
      "Net: the\n",
      "Txt: this\n",
      "Net: the\n",
      "Txt: truth\n",
      "Net: the\n",
      "Txt: is\n",
      "Net: the\n",
      "Txt: so\n",
      "Net: the\n",
      "Txt: well\n",
      "Net: the\n",
      "Txt: fixed\n",
      "Net: the\n",
      "Txt: in\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: minds\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: surrounding\n",
      "Net: the\n",
      "Txt: families\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: he\n",
      "Net: the\n",
      "Txt: is\n",
      "Net: the\n",
      "Txt: considered\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: rightful\n",
      "Net: the\n",
      "Txt: property\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: some\n",
      "Net: the\n",
      "Txt: one\n",
      "Net: the\n",
      "Txt: or\n",
      "Net: the\n",
      "Txt: other\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: their\n",
      "Net: the\n",
      "Txt: daughters\n",
      "Net: the\n",
      "Txt: My\n",
      "Net: the\n",
      "Txt: dear\n",
      "Net: the\n",
      "Txt: Mr\n",
      "Net: the\n",
      "Txt: Bennet\n",
      "Net: the\n",
      "Txt: said\n",
      "Net: the\n",
      "Txt: his\n",
      "Net: the\n",
      "Txt: lady\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: him\n",
      "Net: the\n",
      "Txt: one\n",
      "Net: the\n",
      "Txt: day\n",
      "Net: the\n",
      "Txt: have\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: heard\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: Netherfield\n",
      "Net: the\n",
      "Txt: Park\n",
      "Net: the\n",
      "Txt: is\n",
      "Net: the\n",
      "Txt: let\n",
      "Net: the\n",
      "Txt: at\n",
      "Net: the\n",
      "Txt: last\n",
      "Net: the\n",
      "Txt: Mr\n",
      "Net: the\n",
      "Txt: Bennet\n",
      "Net: the\n",
      "Txt: replied\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: he\n",
      "Net: the\n",
      "Txt: had\n",
      "Net: the\n",
      "Txt: not\n",
      "Net: the\n",
      "Txt: But\n",
      "Net: the\n",
      "Txt: it\n",
      "Net: the\n",
      "Txt: is\n",
      "Net: the\n",
      "Txt: returned\n",
      "Net: the\n",
      "Txt: she\n",
      "Net: the\n",
      "Txt: for\n",
      "Net: the\n",
      "Txt: Mrs\n",
      "Net: the\n",
      "Txt: Long\n",
      "Net: the\n",
      "Txt: has\n",
      "Net: the\n",
      "Txt: just\n",
      "Net: the\n",
      "Txt: been\n",
      "Net: the\n",
      "Txt: here\n",
      "Net: the\n",
      "Txt: and\n",
      "Net: the\n",
      "Txt: she\n",
      "Net: the\n",
      "Txt: told\n",
      "Net: the\n",
      "Txt: me\n",
      "Net: the\n",
      "Txt: all\n",
      "Net: the\n",
      "Txt: about\n",
      "Net: the\n",
      "Txt: it\n",
      "Net: the\n",
      "Txt: Mr\n",
      "Net: the\n",
      "Txt: Bennet\n",
      "Net: the\n",
      "Txt: made\n",
      "Net: the\n",
      "Txt: no\n",
      "Net: the\n",
      "Txt: answer\n",
      "Net: the\n",
      "Txt: Do\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: not\n",
      "Net: the\n",
      "Txt: want\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: know\n",
      "Net: the\n",
      "Txt: who\n",
      "Net: the\n",
      "Txt: has\n",
      "Net: the\n",
      "Txt: taken\n",
      "Net: the\n",
      "Txt: it\n",
      "Net: the\n",
      "Txt: cried\n",
      "Net: the\n",
      "Txt: his\n",
      "Net: the\n",
      "Txt: wife\n",
      "Net: the\n",
      "Txt: impatiently\n",
      "Net: the\n",
      "Txt: You\n",
      "Net: the\n",
      "Txt: want\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: tell\n",
      "Net: the\n",
      "Txt: me\n",
      "Net: the\n",
      "Txt: and\n",
      "Net: the\n",
      "Txt: I\n",
      "Net: the\n",
      "Txt: have\n",
      "Net: the\n",
      "Txt: no\n",
      "Net: the\n",
      "Txt: objection\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: hearing\n",
      "Net: the\n",
      "Txt: it\n",
      "Net: the\n",
      "Txt: This\n",
      "Net: the\n",
      "Txt: was\n",
      "Net: the\n",
      "Txt: invitation\n",
      "Net: the\n",
      "Txt: enough\n",
      "Net: the\n",
      "Txt: Why\n",
      "Net: the\n",
      "Txt: my\n",
      "Net: the\n",
      "Txt: dear\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: must\n",
      "Net: the\n",
      "Txt: know\n",
      "Net: the\n",
      "Txt: Mrs\n",
      "Net: the\n",
      "Txt: Long\n",
      "Net: the\n",
      "Txt: says\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: Netherfield\n",
      "Net: the\n",
      "Txt: is\n",
      "Net: the\n",
      "Txt: taken\n",
      "Net: the\n",
      "Txt: by\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: young\n",
      "Net: the\n",
      "Txt: man\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: large\n",
      "Net: the\n",
      "Txt: fortune\n",
      "Net: the\n",
      "Txt: from\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: north\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: England\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: he\n",
      "Net: the\n",
      "Txt: came\n",
      "Net: the\n",
      "Txt: down\n",
      "Net: the\n",
      "Txt: on\n",
      "Net: the\n",
      "Txt: Monday\n",
      "Net: the\n",
      "Txt: in\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: chaise\n",
      "Net: the\n",
      "Txt: and\n",
      "Net: the\n",
      "Txt: four\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: see\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: place\n",
      "Net: the\n",
      "Txt: and\n",
      "Net: the\n",
      "Txt: was\n",
      "Net: the\n",
      "Txt: so\n",
      "Net: the\n",
      "Txt: much\n",
      "Net: the\n",
      "Txt: delighted\n",
      "Net: the\n",
      "Txt: with\n",
      "Net: the\n",
      "Txt: it\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: he\n",
      "Net: the\n",
      "Txt: agreed\n",
      "Net: the\n",
      "Txt: with\n",
      "Net: the\n",
      "Txt: Mr\n",
      "Net: the\n",
      "Txt: Morris\n",
      "Net: the\n",
      "Txt: immediately\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: he\n",
      "Net: the\n",
      "Txt: is\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: take\n",
      "Net: the\n",
      "Txt: possession\n",
      "Net: the\n",
      "Txt: before\n",
      "Net: the\n",
      "Txt: Michaelmas\n",
      "Net: the\n",
      "Txt: and\n",
      "Net: the\n",
      "Txt: some\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: his\n",
      "Net: the\n",
      "Txt: servants\n",
      "Net: the\n",
      "Txt: are\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: be\n",
      "Net: the\n",
      "Txt: in\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: house\n",
      "Net: the\n",
      "Txt: by\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: end\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: next\n",
      "Net: the\n",
      "Txt: week\n",
      "Net: the\n",
      "Txt: What\n",
      "Net: the\n",
      "Txt: is\n",
      "Net: the\n",
      "Txt: his\n",
      "Net: the\n",
      "Txt: name\n",
      "Net: the\n",
      "Txt: Bingley\n",
      "Net: the\n",
      "Txt: Is\n",
      "Net: the\n",
      "Txt: he\n",
      "Net: the\n",
      "Txt: married\n",
      "Net: the\n",
      "Txt: or\n",
      "Net: the\n",
      "Txt: single\n",
      "Net: the\n",
      "Txt: Oh\n",
      "Net: the\n",
      "Txt: Single\n",
      "Net: the\n",
      "Txt: my\n",
      "Net: the\n",
      "Txt: dear\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: be\n",
      "Net: the\n",
      "Txt: sure\n",
      "Net: the\n",
      "Txt: A\n",
      "Net: the\n",
      "Txt: single\n",
      "Net: the\n",
      "Txt: man\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: large\n",
      "Net: the\n",
      "Txt: fortune\n",
      "Net: the\n",
      "Txt: four\n",
      "Net: the\n",
      "Txt: or\n",
      "Net: the\n",
      "Txt: five\n",
      "Net: the\n",
      "Txt: thousand\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: year\n",
      "Net: the\n",
      "Txt: What\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: fine\n",
      "Net: the\n",
      "Txt: thing\n",
      "Net: the\n",
      "Txt: for\n",
      "Net: the\n",
      "Txt: our\n",
      "Net: the\n",
      "Txt: girls\n",
      "Net: the\n",
      "Txt: How\n",
      "Net: the\n",
      "Txt: so\n",
      "Net: the\n",
      "Txt: How\n",
      "Net: the\n",
      "Txt: can\n",
      "Net: the\n",
      "Txt: it\n",
      "Net: the\n",
      "Txt: affect\n",
      "Net: the\n",
      "Txt: them\n",
      "Net: the\n",
      "Txt: My\n",
      "Net: the\n",
      "Txt: dear\n",
      "Net: the\n",
      "Txt: Mr\n",
      "Net: the\n",
      "Txt: Bennet\n",
      "Net: the\n",
      "Txt: replied\n",
      "Net: the\n",
      "Txt: his\n",
      "Net: the\n",
      "Txt: wife\n",
      "Net: the\n",
      "Txt: how\n",
      "Net: the\n",
      "Txt: can\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: be\n",
      "Net: the\n",
      "Txt: so\n",
      "Net: the\n",
      "Txt: tiresome\n",
      "Net: the\n",
      "Txt: You\n",
      "Net: the\n",
      "Txt: must\n",
      "Net: the\n",
      "Txt: know\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: I\n",
      "Net: the\n",
      "Txt: am\n",
      "Net: the\n",
      "Txt: thinking\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: his\n",
      "Net: the\n",
      "Txt: marrying\n",
      "Net: the\n",
      "Txt: one\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: them\n",
      "Net: the\n",
      "Txt: Is\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: his\n",
      "Net: the\n",
      "Txt: design\n",
      "Net: the\n",
      "Txt: in\n",
      "Net: the\n",
      "Txt: settling\n",
      "Net: the\n",
      "Txt: here\n",
      "Net: the\n",
      "Txt: Design\n",
      "Net: the\n",
      "Txt: Nonsense\n",
      "Net: the\n",
      "Txt: how\n",
      "Net: the\n",
      "Txt: can\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: talk\n",
      "Net: the\n",
      "Txt: so\n",
      "Net: the\n",
      "Txt: But\n",
      "Net: the\n",
      "Txt: it\n",
      "Net: the\n",
      "Txt: is\n",
      "Net: the\n",
      "Txt: very\n",
      "Net: the\n",
      "Txt: likely\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: he\n",
      "Net: the\n",
      "Txt: may\n",
      "Net: the\n",
      "Txt: fall\n",
      "Net: the\n",
      "Txt: in\n",
      "Net: the\n",
      "Txt: love\n",
      "Net: the\n",
      "Txt: with\n",
      "Net: the\n",
      "Txt: one\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: them\n",
      "Net: the\n",
      "Txt: and\n",
      "Net: the\n",
      "Txt: therefore\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: must\n",
      "Net: the\n",
      "Txt: visit\n",
      "Net: the\n",
      "Txt: him\n",
      "Net: the\n",
      "Txt: as\n",
      "Net: the\n",
      "Txt: soon\n",
      "Net: the\n",
      "Txt: as\n",
      "Net: the\n",
      "Txt: he\n",
      "Net: the\n",
      "Txt: comes\n",
      "Net: the\n",
      "Txt: I\n",
      "Net: the\n",
      "Txt: see\n",
      "Net: the\n",
      "Txt: no\n",
      "Net: the\n",
      "Txt: occasion\n",
      "Net: the\n",
      "Txt: for\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: You\n",
      "Net: the\n",
      "Txt: and\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: girls\n",
      "Net: the\n",
      "Txt: may\n",
      "Net: the\n",
      "Txt: go\n",
      "Net: the\n",
      "Txt: or\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: may\n",
      "Net: the\n",
      "Txt: send\n",
      "Net: the\n",
      "Txt: them\n",
      "Net: the\n",
      "Txt: by\n",
      "Net: the\n",
      "Txt: themselves\n",
      "Net: the\n",
      "Txt: which\n",
      "Net: the\n",
      "Txt: perhaps\n",
      "Net: the\n",
      "Txt: will\n",
      "Net: the\n",
      "Txt: be\n",
      "Net: the\n",
      "Txt: still\n",
      "Net: the\n",
      "Txt: better\n",
      "Net: the\n",
      "Txt: for\n",
      "Net: the\n",
      "Txt: as\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: are\n",
      "Net: the\n",
      "Txt: as\n",
      "Net: the\n",
      "Txt: handsome\n",
      "Net: the\n",
      "Txt: as\n",
      "Net: the\n",
      "Txt: any\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: them\n",
      "Net: the\n",
      "Txt: Mr\n",
      "Net: the\n",
      "Txt: Bingley\n",
      "Net: the\n",
      "Txt: may\n",
      "Net: the\n",
      "Txt: like\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: best\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: party\n",
      "Net: the\n",
      "Txt: My\n",
      "Net: the\n",
      "Txt: dear\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: flatter\n",
      "Net: the\n",
      "Txt: me\n",
      "Net: the\n",
      "Txt: I\n",
      "Net: the\n",
      "Txt: certainly\n",
      "Net: the\n",
      "Txt: have\n",
      "Net: the\n",
      "Txt: had\n",
      "Net: the\n",
      "Txt: my\n",
      "Net: the\n",
      "Txt: share\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: beauty\n",
      "Net: the\n",
      "Txt: but\n",
      "Net: the\n",
      "Txt: I\n",
      "Net: the\n",
      "Txt: do\n",
      "Net: the\n",
      "Txt: not\n",
      "Net: the\n",
      "Txt: pretend\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: be\n",
      "Net: the\n",
      "Txt: anything\n",
      "Net: the\n",
      "Txt: extraordinary\n",
      "Net: the\n",
      "Txt: now\n",
      "Net: the\n",
      "Txt: When\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: woman\n",
      "Net: the\n",
      "Txt: has\n",
      "Net: the\n",
      "Txt: five\n",
      "Net: the\n",
      "Txt: grownup\n",
      "Net: the\n",
      "Txt: daughters\n",
      "Net: the\n",
      "Txt: she\n",
      "Net: the\n",
      "Txt: ought\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: give\n",
      "Net: the\n",
      "Txt: over\n",
      "Net: the\n",
      "Txt: thinking\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: her\n",
      "Net: the\n",
      "Txt: own\n",
      "Net: the\n",
      "Txt: beauty\n",
      "Net: the\n",
      "Txt: In\n",
      "Net: the\n",
      "Txt: such\n",
      "Net: the\n",
      "Txt: cases\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: woman\n",
      "Net: the\n",
      "Txt: has\n",
      "Net: the\n",
      "Txt: not\n",
      "Net: the\n",
      "Txt: often\n",
      "Net: the\n",
      "Txt: much\n",
      "Net: the\n",
      "Txt: beauty\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: think\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: But\n",
      "Net: the\n",
      "Txt: my\n",
      "Net: the\n",
      "Txt: dear\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: must\n",
      "Net: the\n",
      "Txt: indeed\n",
      "Net: the\n",
      "Txt: go\n",
      "Net: the\n",
      "Txt: and\n",
      "Net: the\n",
      "Txt: see\n",
      "Net: the\n",
      "Txt: Mr\n",
      "Net: the\n",
      "Txt: Bingley\n",
      "Net: the\n",
      "Txt: when\n",
      "Net: the\n",
      "Txt: he\n",
      "Net: the\n",
      "Txt: comes\n",
      "Net: the\n",
      "Txt: into\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: neighbourhood\n",
      "Net: the\n",
      "Txt: It\n",
      "Net: the\n",
      "Txt: is\n",
      "Net: the\n",
      "Txt: more\n",
      "Net: the\n",
      "Txt: than\n",
      "Net: the\n",
      "Txt: I\n",
      "Net: the\n",
      "Txt: engage\n",
      "Net: the\n",
      "Txt: for\n",
      "Net: the\n",
      "Txt: I\n",
      "Net: the\n",
      "Txt: assure\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: But\n",
      "Net: the\n",
      "Txt: consider\n",
      "Net: the\n",
      "Txt: your\n",
      "Net: the\n",
      "Txt: daughters\n",
      "Net: the\n",
      "Txt: Only\n",
      "Net: the\n",
      "Txt: think\n",
      "Net: the\n",
      "Txt: what\n",
      "Net: the\n",
      "Txt: an\n",
      "Net: the\n",
      "Txt: establishment\n",
      "Net: the\n",
      "Txt: it\n",
      "Net: the\n",
      "Txt: would\n",
      "Net: the\n",
      "Txt: be\n",
      "Net: the\n",
      "Txt: for\n",
      "Net: the\n",
      "Txt: one\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: them\n",
      "Net: the\n",
      "Txt: Sir\n",
      "Net: the\n",
      "Txt: William\n",
      "Net: the\n",
      "Txt: and\n",
      "Net: the\n",
      "Txt: Lady\n",
      "Net: the\n",
      "Txt: Lucas\n",
      "Net: the\n",
      "Txt: are\n",
      "Net: the\n",
      "Txt: determined\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: go\n",
      "Net: the\n",
      "Txt: merely\n",
      "Net: the\n",
      "Txt: on\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: account\n",
      "Net: the\n",
      "Txt: for\n",
      "Net: the\n",
      "Txt: in\n",
      "Net: the\n",
      "Txt: general\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: know\n",
      "Net: the\n",
      "Txt: they\n",
      "Net: the\n"
     ]
    }
   ],
   "source": [
    "# Iterate - teacher forcing through each line\n",
    "for i in range(0,nwords):\n",
    "    # Get the gestalt context for the input sequence(s)\n",
    "    context=encoder_model.predict(X[i:i+1,:,:])\n",
    "    \n",
    "    # Prep a starting token...\n",
    "    token=encode_seq('',stoi)[0].reshape(1,1,len(stoi))\n",
    "    \n",
    "    result=np.zeros([1,postY.shape[1],postY.shape[2]])\n",
    "    \"\"\"\n",
    "    for x in range(postY.shape[1]):\n",
    "        out,h,c = decoder_model.predict([token]+context)\n",
    "        token[:,:,:] = 0.0\n",
    "        token[:,:,np.argmax(out)] = 1.0\n",
    "        context = [h,c]\n",
    "        result[:,x,:] = token\n",
    "        if decode_seq(token,itos) == '':\n",
    "            break\n",
    "    \n",
    "    \"\"\"\n",
    "    for x in range(postY.shape[1]):\n",
    "        out,h,c=decoder_model.predict([token]+context)\n",
    "        token=np.round(out)\n",
    "        context=[h,c]\n",
    "        result[:,x,:]=token\n",
    "    \n",
    "    print('Txt:',text[i+1])\n",
    "    print('Net:',decode_seq(result[0,:,:],itos))\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test your networks without using teacher forcing (500 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Txt: is\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: truth\n",
      "Net: the\n",
      "Txt: universally\n",
      "Net: the\n",
      "Txt: acknowledged\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: single\n",
      "Net: the\n",
      "Txt: man\n",
      "Net: the\n",
      "Txt: in\n",
      "Net: the\n",
      "Txt: possession\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: good\n",
      "Net: the\n",
      "Txt: fortune\n",
      "Net: the\n",
      "Txt: must\n",
      "Net: the\n",
      "Txt: be\n",
      "Net: the\n",
      "Txt: in\n",
      "Net: the\n",
      "Txt: want\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: wife\n",
      "Net: the\n",
      "Txt: However\n",
      "Net: the\n",
      "Txt: little\n",
      "Net: the\n",
      "Txt: known\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: feelings\n",
      "Net: the\n",
      "Txt: or\n",
      "Net: the\n",
      "Txt: views\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: such\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: man\n",
      "Net: the\n",
      "Txt: may\n",
      "Net: the\n",
      "Txt: be\n",
      "Net: the\n",
      "Txt: on\n",
      "Net: the\n",
      "Txt: his\n",
      "Net: the\n",
      "Txt: first\n",
      "Net: the\n",
      "Txt: entering\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: neighbourhood\n",
      "Net: the\n",
      "Txt: this\n",
      "Net: the\n",
      "Txt: truth\n",
      "Net: the\n",
      "Txt: is\n",
      "Net: the\n",
      "Txt: so\n",
      "Net: the\n",
      "Txt: well\n",
      "Net: the\n",
      "Txt: fixed\n",
      "Net: the\n",
      "Txt: in\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: minds\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: surrounding\n",
      "Net: the\n",
      "Txt: families\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: he\n",
      "Net: the\n",
      "Txt: is\n",
      "Net: the\n",
      "Txt: considered\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: rightful\n",
      "Net: the\n",
      "Txt: property\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: some\n",
      "Net: the\n",
      "Txt: one\n",
      "Net: the\n",
      "Txt: or\n",
      "Net: the\n",
      "Txt: other\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: their\n",
      "Net: the\n",
      "Txt: daughters\n",
      "Net: the\n",
      "Txt: My\n",
      "Net: the\n",
      "Txt: dear\n",
      "Net: the\n",
      "Txt: Mr\n",
      "Net: the\n",
      "Txt: Bennet\n",
      "Net: the\n",
      "Txt: said\n",
      "Net: the\n",
      "Txt: his\n",
      "Net: the\n",
      "Txt: lady\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: him\n",
      "Net: the\n",
      "Txt: one\n",
      "Net: the\n",
      "Txt: day\n",
      "Net: the\n",
      "Txt: have\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: heard\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: Netherfield\n",
      "Net: the\n",
      "Txt: Park\n",
      "Net: the\n",
      "Txt: is\n",
      "Net: the\n",
      "Txt: let\n",
      "Net: the\n",
      "Txt: at\n",
      "Net: the\n",
      "Txt: last\n",
      "Net: the\n",
      "Txt: Mr\n",
      "Net: the\n",
      "Txt: Bennet\n",
      "Net: the\n",
      "Txt: replied\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: he\n",
      "Net: the\n",
      "Txt: had\n",
      "Net: the\n",
      "Txt: not\n",
      "Net: the\n",
      "Txt: But\n",
      "Net: the\n",
      "Txt: it\n",
      "Net: the\n",
      "Txt: is\n",
      "Net: the\n",
      "Txt: returned\n",
      "Net: the\n",
      "Txt: she\n",
      "Net: the\n",
      "Txt: for\n",
      "Net: the\n",
      "Txt: Mrs\n",
      "Net: the\n",
      "Txt: Long\n",
      "Net: the\n",
      "Txt: has\n",
      "Net: the\n",
      "Txt: just\n",
      "Net: the\n",
      "Txt: been\n",
      "Net: the\n",
      "Txt: here\n",
      "Net: the\n",
      "Txt: and\n",
      "Net: the\n",
      "Txt: she\n",
      "Net: the\n",
      "Txt: told\n",
      "Net: the\n",
      "Txt: me\n",
      "Net: the\n",
      "Txt: all\n",
      "Net: the\n",
      "Txt: about\n",
      "Net: the\n",
      "Txt: it\n",
      "Net: the\n",
      "Txt: Mr\n",
      "Net: the\n",
      "Txt: Bennet\n",
      "Net: the\n",
      "Txt: made\n",
      "Net: the\n",
      "Txt: no\n",
      "Net: the\n",
      "Txt: answer\n",
      "Net: the\n",
      "Txt: Do\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: not\n",
      "Net: the\n",
      "Txt: want\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: know\n",
      "Net: the\n",
      "Txt: who\n",
      "Net: the\n",
      "Txt: has\n",
      "Net: the\n",
      "Txt: taken\n",
      "Net: the\n",
      "Txt: it\n",
      "Net: the\n",
      "Txt: cried\n",
      "Net: the\n",
      "Txt: his\n",
      "Net: the\n",
      "Txt: wife\n",
      "Net: the\n",
      "Txt: impatiently\n",
      "Net: the\n",
      "Txt: You\n",
      "Net: the\n",
      "Txt: want\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: tell\n",
      "Net: the\n",
      "Txt: me\n",
      "Net: the\n",
      "Txt: and\n",
      "Net: the\n",
      "Txt: I\n",
      "Net: the\n",
      "Txt: have\n",
      "Net: the\n",
      "Txt: no\n",
      "Net: the\n",
      "Txt: objection\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: hearing\n",
      "Net: the\n",
      "Txt: it\n",
      "Net: the\n",
      "Txt: This\n",
      "Net: the\n",
      "Txt: was\n",
      "Net: the\n",
      "Txt: invitation\n",
      "Net: the\n",
      "Txt: enough\n",
      "Net: the\n",
      "Txt: Why\n",
      "Net: the\n",
      "Txt: my\n",
      "Net: the\n",
      "Txt: dear\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: must\n",
      "Net: the\n",
      "Txt: know\n",
      "Net: the\n",
      "Txt: Mrs\n",
      "Net: the\n",
      "Txt: Long\n",
      "Net: the\n",
      "Txt: says\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: Netherfield\n",
      "Net: the\n",
      "Txt: is\n",
      "Net: the\n",
      "Txt: taken\n",
      "Net: the\n",
      "Txt: by\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: young\n",
      "Net: the\n",
      "Txt: man\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: large\n",
      "Net: the\n",
      "Txt: fortune\n",
      "Net: the\n",
      "Txt: from\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: north\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: England\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: he\n",
      "Net: the\n",
      "Txt: came\n",
      "Net: the\n",
      "Txt: down\n",
      "Net: the\n",
      "Txt: on\n",
      "Net: the\n",
      "Txt: Monday\n",
      "Net: the\n",
      "Txt: in\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: chaise\n",
      "Net: the\n",
      "Txt: and\n",
      "Net: the\n",
      "Txt: four\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: see\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: place\n",
      "Net: the\n",
      "Txt: and\n",
      "Net: the\n",
      "Txt: was\n",
      "Net: the\n",
      "Txt: so\n",
      "Net: the\n",
      "Txt: much\n",
      "Net: the\n",
      "Txt: delighted\n",
      "Net: the\n",
      "Txt: with\n",
      "Net: the\n",
      "Txt: it\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: he\n",
      "Net: the\n",
      "Txt: agreed\n",
      "Net: the\n",
      "Txt: with\n",
      "Net: the\n",
      "Txt: Mr\n",
      "Net: the\n",
      "Txt: Morris\n",
      "Net: the\n",
      "Txt: immediately\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: he\n",
      "Net: the\n",
      "Txt: is\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: take\n",
      "Net: the\n",
      "Txt: possession\n",
      "Net: the\n",
      "Txt: before\n",
      "Net: the\n",
      "Txt: Michaelmas\n",
      "Net: the\n",
      "Txt: and\n",
      "Net: the\n",
      "Txt: some\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: his\n",
      "Net: the\n",
      "Txt: servants\n",
      "Net: the\n",
      "Txt: are\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: be\n",
      "Net: the\n",
      "Txt: in\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: house\n",
      "Net: the\n",
      "Txt: by\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: end\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: next\n",
      "Net: the\n",
      "Txt: week\n",
      "Net: the\n",
      "Txt: What\n",
      "Net: the\n",
      "Txt: is\n",
      "Net: the\n",
      "Txt: his\n",
      "Net: the\n",
      "Txt: name\n",
      "Net: the\n",
      "Txt: Bingley\n",
      "Net: the\n",
      "Txt: Is\n",
      "Net: the\n",
      "Txt: he\n",
      "Net: the\n",
      "Txt: married\n",
      "Net: the\n",
      "Txt: or\n",
      "Net: the\n",
      "Txt: single\n",
      "Net: the\n",
      "Txt: Oh\n",
      "Net: the\n",
      "Txt: Single\n",
      "Net: the\n",
      "Txt: my\n",
      "Net: the\n",
      "Txt: dear\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: be\n",
      "Net: the\n",
      "Txt: sure\n",
      "Net: the\n",
      "Txt: A\n",
      "Net: the\n",
      "Txt: single\n",
      "Net: the\n",
      "Txt: man\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: large\n",
      "Net: the\n",
      "Txt: fortune\n",
      "Net: the\n",
      "Txt: four\n",
      "Net: the\n",
      "Txt: or\n",
      "Net: the\n",
      "Txt: five\n",
      "Net: the\n",
      "Txt: thousand\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: year\n",
      "Net: the\n",
      "Txt: What\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: fine\n",
      "Net: the\n",
      "Txt: thing\n",
      "Net: the\n",
      "Txt: for\n",
      "Net: the\n",
      "Txt: our\n",
      "Net: the\n",
      "Txt: girls\n",
      "Net: the\n",
      "Txt: How\n",
      "Net: the\n",
      "Txt: so\n",
      "Net: the\n",
      "Txt: How\n",
      "Net: the\n",
      "Txt: can\n",
      "Net: the\n",
      "Txt: it\n",
      "Net: the\n",
      "Txt: affect\n",
      "Net: the\n",
      "Txt: them\n",
      "Net: the\n",
      "Txt: My\n",
      "Net: the\n",
      "Txt: dear\n",
      "Net: the\n",
      "Txt: Mr\n",
      "Net: the\n",
      "Txt: Bennet\n",
      "Net: the\n",
      "Txt: replied\n",
      "Net: the\n",
      "Txt: his\n",
      "Net: the\n",
      "Txt: wife\n",
      "Net: the\n",
      "Txt: how\n",
      "Net: the\n",
      "Txt: can\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: be\n",
      "Net: the\n",
      "Txt: so\n",
      "Net: the\n",
      "Txt: tiresome\n",
      "Net: the\n",
      "Txt: You\n",
      "Net: the\n",
      "Txt: must\n",
      "Net: the\n",
      "Txt: know\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: I\n",
      "Net: the\n",
      "Txt: am\n",
      "Net: the\n",
      "Txt: thinking\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: his\n",
      "Net: the\n",
      "Txt: marrying\n",
      "Net: the\n",
      "Txt: one\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: them\n",
      "Net: the\n",
      "Txt: Is\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: his\n",
      "Net: the\n",
      "Txt: design\n",
      "Net: the\n",
      "Txt: in\n",
      "Net: the\n",
      "Txt: settling\n",
      "Net: the\n",
      "Txt: here\n",
      "Net: the\n",
      "Txt: Design\n",
      "Net: the\n",
      "Txt: Nonsense\n",
      "Net: the\n",
      "Txt: how\n",
      "Net: the\n",
      "Txt: can\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: talk\n",
      "Net: the\n",
      "Txt: so\n",
      "Net: the\n",
      "Txt: But\n",
      "Net: the\n",
      "Txt: it\n",
      "Net: the\n",
      "Txt: is\n",
      "Net: the\n",
      "Txt: very\n",
      "Net: the\n",
      "Txt: likely\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: he\n",
      "Net: the\n",
      "Txt: may\n",
      "Net: the\n",
      "Txt: fall\n",
      "Net: the\n",
      "Txt: in\n",
      "Net: the\n",
      "Txt: love\n",
      "Net: the\n",
      "Txt: with\n",
      "Net: the\n",
      "Txt: one\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: them\n",
      "Net: the\n",
      "Txt: and\n",
      "Net: the\n",
      "Txt: therefore\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: must\n",
      "Net: the\n",
      "Txt: visit\n",
      "Net: the\n",
      "Txt: him\n",
      "Net: the\n",
      "Txt: as\n",
      "Net: the\n",
      "Txt: soon\n",
      "Net: the\n",
      "Txt: as\n",
      "Net: the\n",
      "Txt: he\n",
      "Net: the\n",
      "Txt: comes\n",
      "Net: the\n",
      "Txt: I\n",
      "Net: the\n",
      "Txt: see\n",
      "Net: the\n",
      "Txt: no\n",
      "Net: the\n",
      "Txt: occasion\n",
      "Net: the\n",
      "Txt: for\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: You\n",
      "Net: the\n",
      "Txt: and\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: girls\n",
      "Net: the\n",
      "Txt: may\n",
      "Net: the\n",
      "Txt: go\n",
      "Net: the\n",
      "Txt: or\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: may\n",
      "Net: the\n",
      "Txt: send\n",
      "Net: the\n",
      "Txt: them\n",
      "Net: the\n",
      "Txt: by\n",
      "Net: the\n",
      "Txt: themselves\n",
      "Net: the\n",
      "Txt: which\n",
      "Net: the\n",
      "Txt: perhaps\n",
      "Net: the\n",
      "Txt: will\n",
      "Net: the\n",
      "Txt: be\n",
      "Net: the\n",
      "Txt: still\n",
      "Net: the\n",
      "Txt: better\n",
      "Net: the\n",
      "Txt: for\n",
      "Net: the\n",
      "Txt: as\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: are\n",
      "Net: the\n",
      "Txt: as\n",
      "Net: the\n",
      "Txt: handsome\n",
      "Net: the\n",
      "Txt: as\n",
      "Net: the\n",
      "Txt: any\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: them\n",
      "Net: the\n",
      "Txt: Mr\n",
      "Net: the\n",
      "Txt: Bingley\n",
      "Net: the\n",
      "Txt: may\n",
      "Net: the\n",
      "Txt: like\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: best\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: party\n",
      "Net: the\n",
      "Txt: My\n",
      "Net: the\n",
      "Txt: dear\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: flatter\n",
      "Net: the\n",
      "Txt: me\n",
      "Net: the\n",
      "Txt: I\n",
      "Net: the\n",
      "Txt: certainly\n",
      "Net: the\n",
      "Txt: have\n",
      "Net: the\n",
      "Txt: had\n",
      "Net: the\n",
      "Txt: my\n",
      "Net: the\n",
      "Txt: share\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: beauty\n",
      "Net: the\n",
      "Txt: but\n",
      "Net: the\n",
      "Txt: I\n",
      "Net: the\n",
      "Txt: do\n",
      "Net: the\n",
      "Txt: not\n",
      "Net: the\n",
      "Txt: pretend\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: be\n",
      "Net: the\n",
      "Txt: anything\n",
      "Net: the\n",
      "Txt: extraordinary\n",
      "Net: the\n",
      "Txt: now\n",
      "Net: the\n",
      "Txt: When\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: woman\n",
      "Net: the\n",
      "Txt: has\n",
      "Net: the\n",
      "Txt: five\n",
      "Net: the\n",
      "Txt: grownup\n",
      "Net: the\n",
      "Txt: daughters\n",
      "Net: the\n",
      "Txt: she\n",
      "Net: the\n",
      "Txt: ought\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: give\n",
      "Net: the\n",
      "Txt: over\n",
      "Net: the\n",
      "Txt: thinking\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: her\n",
      "Net: the\n",
      "Txt: own\n",
      "Net: the\n",
      "Txt: beauty\n",
      "Net: the\n",
      "Txt: In\n",
      "Net: the\n",
      "Txt: such\n",
      "Net: the\n",
      "Txt: cases\n",
      "Net: the\n",
      "Txt: a\n",
      "Net: the\n",
      "Txt: woman\n",
      "Net: the\n",
      "Txt: has\n",
      "Net: the\n",
      "Txt: not\n",
      "Net: the\n",
      "Txt: often\n",
      "Net: the\n",
      "Txt: much\n",
      "Net: the\n",
      "Txt: beauty\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: think\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: But\n",
      "Net: the\n",
      "Txt: my\n",
      "Net: the\n",
      "Txt: dear\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: must\n",
      "Net: the\n",
      "Txt: indeed\n",
      "Net: the\n",
      "Txt: go\n",
      "Net: the\n",
      "Txt: and\n",
      "Net: the\n",
      "Txt: see\n",
      "Net: the\n",
      "Txt: Mr\n",
      "Net: the\n",
      "Txt: Bingley\n",
      "Net: the\n",
      "Txt: when\n",
      "Net: the\n",
      "Txt: he\n",
      "Net: the\n",
      "Txt: comes\n",
      "Net: the\n",
      "Txt: into\n",
      "Net: the\n",
      "Txt: the\n",
      "Net: the\n",
      "Txt: neighbourhood\n",
      "Net: the\n",
      "Txt: It\n",
      "Net: the\n",
      "Txt: is\n",
      "Net: the\n",
      "Txt: more\n",
      "Net: the\n",
      "Txt: than\n",
      "Net: the\n",
      "Txt: I\n",
      "Net: the\n",
      "Txt: engage\n",
      "Net: the\n",
      "Txt: for\n",
      "Net: the\n",
      "Txt: I\n",
      "Net: the\n",
      "Txt: assure\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: But\n",
      "Net: the\n",
      "Txt: consider\n",
      "Net: the\n",
      "Txt: your\n",
      "Net: the\n",
      "Txt: daughters\n",
      "Net: the\n",
      "Txt: Only\n",
      "Net: the\n",
      "Txt: think\n",
      "Net: the\n",
      "Txt: what\n",
      "Net: the\n",
      "Txt: an\n",
      "Net: the\n",
      "Txt: establishment\n",
      "Net: the\n",
      "Txt: it\n",
      "Net: the\n",
      "Txt: would\n",
      "Net: the\n",
      "Txt: be\n",
      "Net: the\n",
      "Txt: for\n",
      "Net: the\n",
      "Txt: one\n",
      "Net: the\n",
      "Txt: of\n",
      "Net: the\n",
      "Txt: them\n",
      "Net: the\n",
      "Txt: Sir\n",
      "Net: the\n",
      "Txt: William\n",
      "Net: the\n",
      "Txt: and\n",
      "Net: the\n",
      "Txt: Lady\n",
      "Net: the\n",
      "Txt: Lucas\n",
      "Net: the\n",
      "Txt: are\n",
      "Net: the\n",
      "Txt: determined\n",
      "Net: the\n",
      "Txt: to\n",
      "Net: the\n",
      "Txt: go\n",
      "Net: the\n",
      "Txt: merely\n",
      "Net: the\n",
      "Txt: on\n",
      "Net: the\n",
      "Txt: that\n",
      "Net: the\n",
      "Txt: account\n",
      "Net: the\n",
      "Txt: for\n",
      "Net: the\n",
      "Txt: in\n",
      "Net: the\n",
      "Txt: general\n",
      "Net: the\n",
      "Txt: you\n",
      "Net: the\n",
      "Txt: know\n",
      "Net: the\n",
      "Txt: they\n",
      "Net: the\n"
     ]
    }
   ],
   "source": [
    "# Iterate - but no teaching forcing past first line...\n",
    "# Get the gestalt context for the input sequence\n",
    "i=0\n",
    "context=encoder_model.predict(X[i:i+1,:,:])\n",
    "for i in range(0,nwords):\n",
    "    # Prep a starting token...\n",
    "    token=encode_seq('',stoi)[0].reshape(1,1,len(stoi))\n",
    "    \n",
    "    result=np.zeros([1,postY.shape[1],postY.shape[2]])\n",
    "    \"\"\"\n",
    "    for x in range(postY.shape[1]):\n",
    "        out,h,c = decoder_model.predict([token]+context)\n",
    "        token[:,:,:] = 0.0\n",
    "        token[:,:,np.argmax(out)] = 1.0\n",
    "        context = [h,c]\n",
    "        result[:,x,:] = token\n",
    "        if decode_seq(token,itos) == '':\n",
    "            break\n",
    "    \n",
    "    \"\"\"\n",
    "    for x in range(postY.shape[1]):\n",
    "        out,h,c=decoder_model.predict([token]+context)\n",
    "        token=np.round(out)\n",
    "        context=[h,c]\n",
    "        result[:,x,:]=token\n",
    "    \n",
    "    print('Txt:',text[i+1])\n",
    "    print('Net:',decode_seq(result[0,:,:],itos))\n",
    "    \n",
    "    # CRUCIAL -> keep predicted result instead of teacher forcing!\n",
    "    context=encoder_model.predict(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Describe any differences in the learning behaviours observed from Problems 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2 seemed easier to nail down than problem 1 for me, although that may just be because there were less parameters in 2, so I could train and test it easier. I spent at least 2-3 days working on this, staring at the output trying to get sentences and words to come out either non-jumbled or non-' '. After applying argmax instead of round, the output seemed better. The models are extremely easy to overtrain even then, to only spitting out the same word/sentence over and over again. Jupyter is also being crazy slow tonight, sometimes not even loading the model into memory. I've been watching top and a lot of the RAM and CPU are being eaten up on all of the jupyters (I usually do the labs early, so I guess this must be normal.) I couldn't get the models to work like how I wanted, but I'm going to turn it in for now because the deadline is almost here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
